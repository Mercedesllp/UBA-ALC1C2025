{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb8c4d4",
   "metadata": {},
   "source": [
    "# Reducción de la dimensionalidad a través de Descomposición en Valores Singulares (SVD)\n",
    "\n",
    "En este notebook vamos a explorar dos aplicaciones de descomposición en valores singulares (SVD por sus siglas en inglés) a reducción de la dimensión de datasets. La metodología es realmente muy útil, con montones de aplicaciones a análisis de imágenes, reconstrucción de sistemas dinámicos, detección de comunidades en redes, reducción de la dimensión de datasets extensos, y muchas otras. Recordemos que dada una matriz $A \\in \\mathbb{R}^{n \\times m}$, se puede factorizar como\n",
    "\n",
    "$$\n",
    "A = U \\Sigma V^t\n",
    "$$\n",
    "\n",
    "donde $U\\in\\mathbb{R}^{n \\times n}$ y $V\\in\\mathbb{R}^{m \\times m}$ son matrices ortogonales, y $\\Sigma \\in \\mathbb{R}^{n \\times m}$ es una matriz diagonal con elementos $\\sigma_i \\geq 0$ en su diagonal, denominados valores singulares. El rango de la matriz $rank(A)=r$ es igual al número de valores singulares distintos de cero. Dado que los valores singulares están ordenados de manera decreciente por construcción, tenemos que $\\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq \\sigma_r> \\sigma_{r+1}=0$.\n",
    "\n",
    "Las matrices $U$  y $V$ nos proveen (a través de sus columnas) de bases ortonormales del espacio de partida y del de llegada. Dado que los valores singulares posteriores al $r$ son cero, a veces se escribe una versión reducida de la matriz, que sólo incluye la información relevante. En ese caso, tenemos $\\tilde \\Sigma \\in \\mathbb{R}^{r \\times r}$, una matriz diagonal cuadrada, con los elementos $\\sigma_1,\\dots,\\sigma_r$ en la diagonal, y $\\tilde U \\in \\mathbb{R}^{n \\times r}$, con las primeras $r$ columnas de $U$, y $\\tilde V \\in \\mathbb{R}^{m \\times r}$, con las primeras $r$ columnas de $V$. Por último, recordemos que la mejor aproximación de una matriz en norma 2 por una de rango $s\\leq r$ está dada por la versión reducida de su descomposición SVD incluyendo hasta $s$ valores singulares (en orden decreciente). Notaremos a esta aproximación $A_s = \\tilde U_s \\tilde \\Sigma_s \\tilde V^t_s$, donde $\\tilde U_s \\in \\mathbb{R}^{n \\times s}$, $\\tilde \\Sigma_s \\in \\mathbb{R}^{s \\times s}$ y  $\\tilde V_s \\in \\mathbb{R}^{m \\times s}$ se definen de forma análoga a la versión reducida, pero tomando sólo $s$ columnas y valores singulares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f0612",
   "metadata": {},
   "source": [
    "## Aplicación 1: \"Compresión\" de imágenes\n",
    "\n",
    "Uno de los ejemplos típicos que se emplea para demostrar el poder de reducción del tamaño de un dataset usando SVD es el de compresión de imágenes. Si bien no es un método muy usado para comprimir imágenes, su aplicación sirve de punto de partida para métodos más sofisticados. Por ejemplo, [_Dynamic Mode Decomposition_](https://en.wikipedia.org/wiki/Dynamic_mode_decomposition) emplea estas ideas como punto de partida para identificar movimientos característicos. Pueden ver un video muy simpático [aquí](https://www.youtube.com/shorts/z2-l6MwATYc) donde se muestran los distintos patrones de movimiento que se van encontrando en el agua.\n",
    "\n",
    "Como motivación, aquí haremos algo más modesto, que es simplemente aplicarlo a imágenes. Para esto, recordemos que una imagen en color puede pensarse como tres matrices (una en rojo, una en verde y una en azul, [RGB](https://en.wikipedia.org/wiki/RGB_color_model)), mientras que una en escala de grises se puede ver directamente como una única matriz. Cada posición $i,j$ de la matriz contiene la intensidad de color (o de gris) de un pixel, mientras que las dimensiones de la matriz representan el tamaño de la imagen. Por simplicidad, consideraremos que tenemos una única matriz $A$ que representa la imagen en escala de grises (el caso general consiste en simplemente en repetir el procedimiento para las matrices asociadas a cada color).\n",
    "\n",
    "Entonces, la major aproximación que podemos obtener de la matriz $A$ usando una matriz de rango $s$ es $A_s$ como lo definimos más arriba. Pongamos esto a prueba para algunas imágenes, y exploremos qué tal resulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes para trabajar con imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558908fe",
   "metadata": {},
   "source": [
    "Empezamos leyendo la imagen de un árbol que acompaña el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el archivo\n",
    "img = io.imread('tree2.jpg')\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f6892",
   "metadata": {},
   "source": [
    "Observen la forma general de la imagen, así como los detalles que incluye. Para la compresión vamos a convertirla a escala de grises, lo cual ya implica una pérdida de información (aunque muchos detalles se preservan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo convertimos a tonos de gris para simplificar la aplicación\n",
    "imgGray = color.rgb2gray(img)\n",
    "print(imgGray.shape)\n",
    "\n",
    "plt.imshow(imgGray, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de7047",
   "metadata": {},
   "source": [
    "Revisemos cuales son los tamaños que dispone la imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('La imagen tiene ' + str(imgGray.shape[0]) + ' x ' + str(imgGray.shape[1]) +' pixeles')\n",
    "print('Es decir, tenemos ' + str(np.prod(imgGray.shape)) + ' pixeles')\n",
    "print('El rango de la matriz es ' + str(np.linalg.matrix_rank(imgGray)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bacfbc6",
   "metadata": {},
   "source": [
    "Fijense que si el rango de la matriz es $r$, entonces podemos almacenar toda su información con $r$ valores singulares, más una matriz de $\\mathbb{R}^{n \\times r}$, más otra de $\\mathbb{R}^{m \\times r}$. Es decir, necesitamos $r + nr + mr = (n + m + 1)r$ números. Por otro lado, la imagen original requiere guardar $nm$ elementos. Dependiendo del rango de la matriz, la versión SVD reducida ya nos salvaría espacio. Sin embargo, si el rango es grande, la versión reducida requiere más espacio que la matriz original. Este es el caso de la imagen del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de33a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio de compresion\n",
    "tamanioRed = (imgGray.shape[0] + imgGray.shape[1] + 1)* np.linalg.matrix_rank(imgGray)\n",
    "tamanioOrig = imgGray.shape[0] * imgGray.shape[1]\n",
    "print(tamanioRed)\n",
    "print(tamanioOrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrank = np.linalg.matrix_rank(imgGray)\n",
    "plt.plot(range(0,mrank),(imgGray.shape[0] + imgGray.shape[1] + 1)*np.arange(0,mrank),label='Tamaño $A_s$')\n",
    "plt.plot([0,mrank],2*[imgGray.shape[0] * imgGray.shape[1]],label='Tamaño A')\n",
    "plt.xlabel('Rango $s$')\n",
    "plt.ylabel('Cantidad de  números a almacenar')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db8d6f",
   "metadata": {},
   "source": [
    "Podemos ver que recién alrededor de $s=700$ (es decir, reducir el rango en 287), puede empezar a ganar espacio en la memoria. La pregunta es: ¿son significativos esos casi 300 valores singulares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b668a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculemos la descomposición de la imagen\n",
    "\n",
    "U,S,Vt = np.linalg.svd(imgGray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8198076",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(S)),S)\n",
    "plt.xlabel('Posición $i$')\n",
    "plt.ylabel('Valor singular $\\sigma_i$')\n",
    "#plt.yscale('log') # Prueben poner y sacar escala log para comparar\n",
    "#plt.xlim(-1,20) # Prueben poner y sacar para comparar\n",
    "#plt.xlim(970,1000) # Prueben poner y sacar para comparar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282ba3d",
   "metadata": {},
   "source": [
    "Podemos ver que hay tres regimenes: hay un primer conjunto de valores singulares muy significativo (podemos decir que los primeros $5$). Luego observamos un decrecimiento suave desde $10$ hasta $1/100$, y al llegar al rango de la matriz una caida abrupta a $10^{-12}$. Con lo cual, pareciera que el grueso de la información se encuentra en los primeros valores singulares. Otra forma de graficar esto mismo que es muy común, es como la suma acumulada de los valores singulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e05b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(S)),np.cumsum(S)/sum(S))\n",
    "plt.xlabel('Posición $i$')\n",
    "plt.ylabel('Acumulado de los valores singulares $\\sigma_i$, normalizado a 1')\n",
    "plt.plot([10,10],[0,1],'k')\n",
    "plt.plot([50,50],[0,1],'k')\n",
    "plt.plot([100,100],[0,1],'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536cbb7",
   "metadata": {},
   "source": [
    "Este gráfico nos muestra que con 100 valores singulares, por ejemplo, ya alcazamos a capturar el 80% de la norma 2 de la matriz. Con solo 10, ya tenemos el 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b133cf",
   "metadata": {},
   "source": [
    "Lo que sigue es ver como se ven las imágenes que obtendriamos en cada caso. Más allá de cuánto capturemos de la norma, si la imagen no es buena, el método no sería útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos una función que reciba un rango s y devuelva la matriz aproximada hasta rango s\n",
    "\n",
    "def hasta_rango_s(svdA,s):\n",
    "    # svdA es la descomposición SVD de A, s es el rango que se desea preservar\n",
    "    U,S,Vt = svdA \n",
    "    As = U[:,:s] @ np.diag(S[:s,]) @ Vt[:s,:]\n",
    "    return(As)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdimgGray = np.linalg.svd(imgGray) # Computamos la SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rango_s = 10 # Prueben distintos valores\n",
    "fig,ax = plt.subplots(1,3,figsize=(20,20))\n",
    "ax[0].imshow(imgGray, cmap='gray')\n",
    "imgGray_s = hasta_rango_s(svdimgGray,rango_s)\n",
    "ax[1].imshow(imgGray_s, cmap='gray')\n",
    "ax[2].imshow(imgGray-imgGray_s, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c239e",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Comparen las imágenes que se obtienen conforme van agregando detalle a la imagen. ¿Qué diferencias notan? ¿Cuántos valores singulares necesito para ganar detalle en las hojas del árbol?¿Cómo cambia la diferencia entre imágenes con el número de valores singulares?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f182adb",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Hagan una grilla de graficos, mostrando 10 valores equiespaciados en escala logaritmica de rango $s$ entre 1 y el rango de la imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba145ab",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Muestren como cambia el error máximo de la aproximación SVD con la cantidad de valores singulares considerados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0264bd",
   "metadata": {},
   "source": [
    "### Ejercicio: Otras imágenes\n",
    "\n",
    "Prueben repetir el ejercicio anterior con otras imágenes. Identifiquen qué cantidad de valores singulares son necesarios para captar aproximar bien cada una. Caracterizen cualitativamente qué tipo de detalles hacen que una imagen requiera más valores singulares para ser bien aproximada visualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a9985a",
   "metadata": {},
   "source": [
    "## Aplicación 2: Análisis de componentes principales\n",
    "\n",
    "Otra de las aplicaciones típicas de SVD es el cálculo de componentes principales en un dataset. La idea del análisis de componentes principales se centra en aplicar SVD a la matriz de [covarianza de los datos](https://es.wikipedia.org/wiki/Covarianza). La matriz de covarianza captura en su diagonal la [varianza](https://es.wikipedia.org/wiki/Varianza) de cada uno de las variables de interés, y en sus elementos fuera de la diagonal captura cómo estas están relacionadas.\n",
    "\n",
    "En este caso, nuestro punto de partida es un conjunto de $m$ [variables aleatorias](https://es.wikipedia.org/wiki/Variable_aleatoria) $X_1,\\dots,X_m$. Suponemos que tenemos $n$ mediciones de cada una de ellas, $x_{ij}$, con $1\\leq i \\leq n$ y $1 \\leq j \\leq m$ (es decir, $x_ij$ es la realización o medición $i$ esima de $X_j$). Podemos acomodar estas mediciones en una matriz $A \\in \\mathbb{R}^{n \\times m}$, con $n$ el número de observaciones, y $m$ el número de variables, y por lo tanto $A_{ij} = x_{ij}$.\n",
    "\n",
    "El análisis de componentes principales empieza por calcular la versión centrada y escalada de $A$, donde\n",
    "\n",
    "$$\n",
    "\\tilde A_{ij} = \\frac{x_{ij} - \\mu_j}{\\frac{1}{n-1}\\sqrt{\\sum^n_{i=1}(x_{ij} - \\mu_j )^2}}\n",
    "$$\n",
    "donde $\\mu_j = \\frac{1}{n} \\sum^n_{i=1} x_{ij}$ es el promedio muestral, $(x_{ij} - \\mu_j )^2$ es una estimación de la varianza muestral (y su raíz una estimación del desvio estandar). Entonces, $S= A^tA \\in \\mathbb{R}^{m \\times m}$ es una estimación de la matriz de [correlaciones](https://es.wikipedia.org/wiki/Correlaci%C3%B3n) de las variables aleatorias $X_1,\\dots,X_m$. Los autovalores de $S$ son los valores singulares de $A$ al cuadrado, y nos permiten identificar qué combinaciones lineales de las variables $X_1,\\dots,X_m$ están asociadas a la mayor variabilidad de los datos.\n",
    "\n",
    "Intuitivamente, si nuestro interés es reducir la dimensión de un dataset, entonces lo que queremos hacer es pasar de un conjunto de variables $X_1,\\dots,X_m$ a otro $Y_1,\\dots,Y_k$, con $k<m$, donde el conjunto de variables $Y$ almacenan el grueso de información de las variables $X$. Usando SVD sobre la matriz $A$ (o sobre la matriz $S$) podemos encontrar las variables $Y$ que son combinación lineal de las $X$ y capturan el grueso de la variabilidad de las $X$ (que en este caso se asocia a la cantidad de información que aportan a un dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ca5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos un caso bastante extremo, tenemos 5 variables donde en realidad todas son proporcionales entre sí (más algo de ruido)\n",
    "\n",
    "n = 100 # Tamaño del dataset\n",
    "Vcoef = np.asarray([50,-30,60,80,150]) # Coeficientes de combinaciones lineales\n",
    "escala_ruido=1\n",
    "X0 = np.random.uniform(size=n) # Esta sería la variable \"escondida\", la única dimensión del problema\n",
    "A = np.asarray([  # Todas las observaciones salen de la misma variable, más un poco de ruido\n",
    "    coe*X0 + np.random.normal(0,escala_ruido,size=n) for coe in Vcoef\n",
    "]).T\n",
    "\n",
    "tildeA = (A - np.mean(A,axis=0))/np.std(A,axis=0) # Normalizamos las columnas y filas para que todo estén alrededor del [-1,1]\n",
    "\n",
    "U,Sigma,Vt = np.linalg.svd(tildeA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061861fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos como se ven las variables antes de seguir\n",
    "\n",
    "fig,axs = plt.subplots(tildeA.shape[1],tildeA.shape[1])\n",
    "for i in range(tildeA.shape[1]):\n",
    "    for j in range(tildeA.shape[1]):\n",
    "        if i == j :\n",
    "            axs[i][j].hist(tildeA[:,i])\n",
    "        elif i<j:\n",
    "            axs[i][j].scatter(tildeA[:,i],tildeA[:,j])\n",
    "        else:\n",
    "            fig.delaxes(axs[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe0743",
   "metadata": {},
   "source": [
    "La correlación lineal en este ejemplo es muy extrema, haciendo muy obvio que en realidad hay una única dimensión en el problema. Si miramos los valores singulares, es inmediato ver que uno destaca por encima del resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ef68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(Sigma)),Sigma)\n",
    "plt.xlabel('Posición $i$')\n",
    "plt.ylabel('Valor singular $\\sigma_i$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38458c38",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Prueben cambiar los coeficientes de las combinaciones lineales, y vean como cambia la distribución de valores singulares. En particular, sabiendo que el ruido agregado es del orden de $1$, vean que pasa cuando los coeficientes son del orden del ruido, o son mucho menores que 1. Observen que pasa si todos los coeficientes son mucho mayores que 1, excepto uno de ellos que es estrictamente 0. Interpreten el resultado en términos del número de valores singulares significativos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e230cc7",
   "metadata": {},
   "source": [
    "En el análisis de componentes principales tiene especial relevancia identificar la combinación lineal de las variables que está asociada al mayor valor singular (vale mencionar que el mayor valor singular es igual a la desviación estandar de dicha combinación lineal). Esto se puede obtener en términos de la matriz $Vt$, siendo su primer fila. En este ejemplo es poco interesante, ya que cualquier combinación lineal de las variables resulta en algo proporcional al $X_0$ del ejemplo. Sin embargo, cuando hay más de una variable relevante nos puede dar información sobre cuales son las variables relevantes subyacentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vean como se recupera la variable latente X0 a través de la primer columna de U\n",
    "plt.scatter(X0,U[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos un ejemplo con dos variables latentes\n",
    "\n",
    "# Veamos un caso bastante extremo, tenemos 5 variables donde en realidad todas son proporcionales entre sí (más algo de ruido)\n",
    "\n",
    "n = 100 # Tamaño del dataset\n",
    "XA = np.random.uniform(size=n) # Esta sería la variable \"escondida\", la única dimensión del problema\n",
    "XB = np.random.uniform(size=n) # Esta sería la variable \"escondida\", la única dimensión del problema\n",
    "A = np.asarray([  # Todas las observaciones salen de la misma variable, más un poco de ruido\n",
    "    50*XA + 25*XA + np.random.normal(0,1,size=n),\n",
    "    -30*XA + 150*XB+ np.random.normal(0,1,size=n),\n",
    "    60*XA - 15*XB + np.random.normal(0,1,size=n),\n",
    "    -5*XA + 80*XB + np.random.normal(0,1,size=n),\n",
    "    -150*XB + 20*XB+ np.random.normal(0,1,size=n)\n",
    "]).T\n",
    "\n",
    "tildeA = (A - np.mean(A,axis=0))/np.std(A,axis=0) # Normalizamos las columnas y filas para que todo estén alrededor del [-1,1]\n",
    "\n",
    "U,Sigma,Vt = np.linalg.svd(tildeA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos como se ven las variables antes de seguir\n",
    "\n",
    "fig,axs = plt.subplots(tildeA.shape[1],tildeA.shape[1])\n",
    "for i in range(tildeA.shape[1]):\n",
    "    for j in range(tildeA.shape[1]):\n",
    "        if i == j :\n",
    "            axs[i][j].hist(tildeA[:,i])\n",
    "        elif i<j:\n",
    "            axs[i][j].scatter(tildeA[:,i],tildeA[:,j])\n",
    "        else:\n",
    "            fig.delaxes(axs[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80341302",
   "metadata": {},
   "source": [
    "En este ejemplo, se puede ver como algunas combinaciones dan lugar a variables muy correlacionadas, y otras que parecieran no estar vinculadas entre sí (las que dan lugar a nubes de puntos). Veamos qué nos dice PCA en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(Sigma)),Sigma)\n",
    "plt.xlabel('Posición $i$')\n",
    "plt.ylabel('Valor singular $\\sigma_i$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf091c4",
   "metadata": {},
   "source": [
    "Pueden ver que el método identifica correctamente que hay solo dos variables latentes que son relevantes, mientras que el resto son \"espureas\". ¿Cuáles son las variables que son relevantes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470964a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "XAB = U[:,:2]\n",
    "# Veamos como se ven las variables antes de seguir\n",
    "\n",
    "fig,axs = plt.subplots(2,2,figsize=(10,10))\n",
    "for i in range(2):\n",
    "    axs[i][0].scatter(XA,XAB[:,i])\n",
    "    axs[i][0].set_xlabel('XA')\n",
    "    axs[i][0].set_ylabel('Columna ' + str(i) + ' de XAB')\n",
    "    axs[i][1].scatter(XB,XAB[:,i])\n",
    "    axs[i][1].set_xlabel('XB')\n",
    "    axs[i][1].set_ylabel('Columna ' + str(i) + ' de XAB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4cb6f",
   "metadata": {},
   "source": [
    "Aquí pueden ver como las dos primeras columnas de $U$, asociadas a las dos primeras componentes de mayor varianza, correlacionan muy bien con $X_A$ y $X_B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfabbd",
   "metadata": {},
   "source": [
    "### Correlaciones no-lineales\n",
    "\n",
    "Lamentablemente, si bien esta es una herramienta extremadamente potente cuando las relaciones son lineales entre las variables, puede fallar estrepitosamente si las relaciones son no-lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183b4e4",
   "metadata": {},
   "source": [
    "Para ejemplificar, construyamos un círculo ruidoso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos un caso bastante extremo, tenemos 5 variables donde en realidad todas son proporcionales entre sí (más algo de ruido)\n",
    "\n",
    "n = 1000 # Tamaño del dataset\n",
    "X0 = np.random.uniform(low=0,high=2*np.pi,size=n) # Esta sería la variable \"escondida\", la única dimensión del problema\n",
    "A = np.asarray([  # Todas las observaciones salen de la misma variable, más un poco de ruido\n",
    "    np.cos(X0) + np.random.normal(0,.1,size=n),\n",
    "    np.sin(X0) + np.random.normal(0,.1,size=n)\n",
    "]).T\n",
    "\n",
    "tildeA = (A - np.mean(A,axis=0))/np.std(A,axis=0) # Normalizamos las columnas y filas para que todo estén alrededor del [-1,1]\n",
    "\n",
    "U,Sigma,Vt = np.linalg.svd(tildeA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos como se ven las variables antes de seguir\n",
    "\n",
    "fig,axs = plt.subplots(tildeA.shape[1],tildeA.shape[1])\n",
    "for i in range(tildeA.shape[1]):\n",
    "    for j in range(tildeA.shape[1]):\n",
    "        if i == j :\n",
    "            axs[i][j].hist(tildeA[:,i])\n",
    "        elif i<j:\n",
    "            axs[i][j].scatter(tildeA[:,i],tildeA[:,j])\n",
    "        else:\n",
    "            fig.delaxes(axs[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff92b15",
   "metadata": {},
   "source": [
    "Viendo esto, es fácil concluir que las variables están relacionadas entre sí. Sin embargo, si miramos las varianzas, son comparables en ambas direcciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532edc8",
   "metadata": {},
   "source": [
    "Esto implica que ambas componentes son significativas. Si graficamos las columnas de $U$ entre sí, vemos que en realidad siguen representando el círculo original. Es decir, no se extrajo nada de información del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(U[:,0],U[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ec44a-6e83-45f4-ae41-b65e2aa3840f",
   "metadata": {},
   "source": [
    "## Eigenfaces\n",
    "\n",
    "Eigenfaces (en español caras propias) es el nombre dado a un conjunto de autovectores cuando se utiliza en el problema de visión artificial del reconocimiento de rostros humanos. Matthew Turk y Alex Pentland lo propusieron en su [paper en la clasificación de caras](https://doi.org/10.1162/jocn.1991.3.1.71).\n",
    "\n",
    "Aquí se muestra como hacer el cálculo del Análisis en Componentes Principales para los datos de los rostros, y luego aplicarlos para la reducción del espacio. Con este nuevo espacio se realizan dos tareas: reconstrucción y clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312e8f6-5e87-4eb3-af56-1607c328bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed7ce52-5c0a-4131-93a5-f96d9be5c67f",
   "metadata": {},
   "source": [
    "Definición de funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c158e-9a7d-4d21-8ed9-274173f2659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(data, label):\n",
    "    # split dataset en entrenamiento y test\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    for train, test in skf.split(data.T, label.T):\n",
    "        break\n",
    "    train_data = data[:,train]\n",
    "    train_lab = label[:,train]\n",
    "    test_data = data[:,test]\n",
    "    test_lab = label[:,test]\n",
    "    \n",
    "    return train_data, train_lab, test_data, test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a90c31b-f7c5-4a05-9c85-b3298ca75cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPic(data, idx, dx=38):\n",
    "    # graficamos una rotro\n",
    "    v = data[:,idx] # primera columna\n",
    "    m = v.reshape((dx,dx)).T\n",
    "    plt.imshow(m, cmap=plt.cm.gray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9352c9-c01e-4216-97d5-65a9f206c55a",
   "metadata": {},
   "source": [
    "La lectura del archivo de datos nos devuelve dos matrices, una correspondiente a las imágenes de los rostros y la otra a un label que indica a cual\n",
    "persona pertenece la imágen.\n",
    "\n",
    "<img src=\"image_vector.png\" />\n",
    "\n",
    "Como vemos en la figura, las imágenes se convirtieron a vector, con N=38 para este set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd6aef-52d5-4e5e-8879-d3af43d2eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('base_40_38_10.mat')\n",
    "# data es una matriz de 1444 x 380.\n",
    "# Corresponde a figuras de caras de tamanio 38x38 pixeles\n",
    "data = mat['data']\n",
    "label = mat['label']\n",
    "# extraemos la dimensionalidad de data, donde n es la cantidad de ejemplos, y d la dimensión del espacio.\n",
    "d, n = data.shape\n",
    "\n",
    "showPic(data, 51)\n",
    "\n",
    "print(label.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4476dee-2edb-406f-b711-a0bb2e33a240",
   "metadata": {},
   "source": [
    "## Análisis de Componentes Principales (ACP o PCA en inglés)\n",
    "\n",
    "Vamos a hacer una modificación respecto del formalismo que usamos en la sección precedente, ya que vamos a acomodar las muestras (los rostros) como columnas.\n",
    "Tampoco vamos a dividir por el desvío estándar ya que las imágenes están acotadas en sus valores de niveles de gris de los pixeles (y por lo tanto están en la misma escala).\n",
    "\n",
    "\n",
    "Primero centramos los valores de las imágenes, restando la media.\n",
    "Luego calculamos la matriz de covarianzas:\n",
    "\n",
    "\n",
    "$C = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu) (x_i - \\mu)^{T}$\n",
    "\n",
    "Finalmente encontramos los autovalores y autovectores de esta matriz, los cuales ordenamos de mayor a menor valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068758b-af24-4170-a24e-b34a6ab62c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculoACP(data):\n",
    "    dx = 38\n",
    "    d, n = data.shape\n",
    "    m=np.mean(data, axis=1)\n",
    "    print(m)\n",
    "    plt.imshow(m.reshape((dx,dx)).T, cmap=plt.cm.gray)\n",
    "    \n",
    "    X = data - np.tile(m.reshape((len(m), 1)), (1, n))\n",
    "    Mcov = np.dot(X,X.T) / n # Covariance Matrix\n",
    "\n",
    "    U, D, Vt = np.linalg.svd(Mcov)\n",
    "    \n",
    "    # ordenamos los autovalores de mayor a menor\n",
    "    idx = np.argsort (- D )\n",
    "    D = D[idx]\n",
    "    U = U[:, idx]\n",
    "\n",
    "    return D, U, X, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e9d78-15c9-4e5b-ace7-c3d1c893d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, U, data_ref, m = calculoACP(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1bffd0",
   "metadata": {},
   "source": [
    "Veamos como se ven las imágenes que quedan representadas en las columnas de U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda3c52-9cfb-4e79-8b5a-2c22c8026f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "showPic(U, 0)\n",
    "print(U[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31bf6c3-c636-4c49-be00-3a2f4b012a7a",
   "metadata": {},
   "source": [
    "El espacio de proyección del ACP esta compuesto por el vector V que es de tamaño $n \\times n$.\n",
    "\n",
    "El próximo paso busca la reducción del espacio de proyección, para quedarnos con aquellos autovectores en V que acumulen la mayor cantidad de información posible en las distintas direcciones.\n",
    "\n",
    "Para ello se hace un cómputo de la varianza acumulada en el vector D, y se selecciona una cantidad que signifique representar un 95 % de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31bd7d5-e661-412d-81d4-f94cd84164eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.cumsum(D) / np.sum(D)\n",
    "plt.plot(ratio)\n",
    "x = np.where(ratio > 0.95)[0]\n",
    "M = x[0]\n",
    "\n",
    "print('Cantidad de autovectores de representación al 95 %: ', M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67b035-6901-4168-97a5-6b3eba71b13f",
   "metadata": {},
   "source": [
    "### Reconstrucción de un rostro\n",
    "\n",
    "El hecho que quedarse con menos autovectores para la proyección del espacio, conlleva a una reducción de almacenamiento de la información, pero al mismo tiempo a cometer un error al tratar de reconstruir la imagen original.\n",
    "\n",
    "En este tramo de código representamos visualmente la imagen original y la reconstruida con M autovectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70bd3f-aa74-49cd-819a-80e54e10a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruccion\n",
    "idx_im = 5\n",
    "im_orig = data_ref[:,idx_im]\n",
    "cpM = U[:,0:M].T @ im_orig \n",
    "\n",
    "print(cpM.shape)\n",
    "\n",
    "im_rec = U[:,0:M] @ cpM \n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(im_orig.reshape((38,38)).T, cmap=plt.cm.gray)\n",
    "axes[1].imshow(im_rec.reshape((38,38)).T + m.reshape((38,38)).T, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae89eb5-cf7c-4d96-abd2-6ed5aaec8749",
   "metadata": {},
   "source": [
    "## Clasificación de nuevas imágenes\n",
    "\n",
    "La tarea de clasificación en predecir a quien de las personas de la base de conocimientos pertenece un rostro de testing. Esto lo vamos a realizar gracias a proyectar el rostro de entrada al espacio de ACP y calcular por distancias, cual es rostro más cercano.\n",
    "\n",
    "En primer lugar separamos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44330e-d64d-4138-b122-740d19a55426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clasificacion\n",
    "train_data, train_lab, test_data, test_lab = splitDataset(data, label)\n",
    "Dt, Ut, train_ref, m = calculoACP(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68920aa4",
   "metadata": {},
   "source": [
    "Luego elegimos la cantidad de componentes que vamos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69171a-c117-4d67-9ac1-36c39d7c94e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.cumsum(Dt) / np.sum(Dt)\n",
    "plt.plot(ratio)\n",
    "x = np.where(ratio > 0.95)[0]\n",
    "M = x[0]\n",
    "print('Cantidad de autovectores de representación al 95 % de la base de entrenamiento: ', M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b58ebb",
   "metadata": {},
   "source": [
    "Y por último elegimos la etiqueta en base a la proyección de la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e02c4d-01cc-446a-a947-47952e0f151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clf = train_ref.T @ Ut[:,0:M]   # proyectamos a la base de entrenamiento, de los cuales conocemos a que persona pertenece\n",
    "\n",
    "input_test = test_data[:,0] # vamos a clasificar el primer sujeto de la base de test\n",
    "test_acp = (input_test - m) @ Ut[:,0:M]    # le resto la media y proyecto en el espacio reducido de Vt\n",
    "Q = np.tile(test_acp.reshape((1,-1)), (data_clf.shape[0], 1))  \n",
    "dist = np.linalg.norm(data_clf - Q, axis=1)    # calculo las distancias a cada una de las imágenes de conocimientos proyectadas en el espacio ACP.\n",
    "y = np.argmin(dist)                             # clasificar por el más cercano\n",
    "\n",
    "if test_lab[0][0] == train_lab[0][y]:\n",
    "    print('Clasificacion correcta')\n",
    "else:\n",
    "    print('clasificacion incorrecta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdd01f7-e59a-484b-8ad5-a75219acff66",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Ejecutar el script anterior pero evaluando el error de clasificaciones correctas e incorrectas para todo el test_data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
